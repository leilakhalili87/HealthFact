{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning for health_fact text classification\n",
    "\n",
    "In this notebook I fine tunned a transformer model for classification on health_fact data taken from [health_fact](https://huggingface.co/datasets/health_fact).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leila/.local/lib/python3.6/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pickle as pkl\n",
    "\n",
    "from setting import *  # model parameters\n",
    "import data_prep as dtp  # Loading data to NN and cleaning\n",
    "from bert_model import BERTClass # creating the model\n",
    "\n",
    "# set up device\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "\n",
    "# random seed\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset health_fact (/home/leila/.cache/huggingface/datasets/health_fact/default/1.1.0/99503637e4255bd805f84d57031c18fe4dd88298f00299d56c94fc59ed68ec19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>claim_id</th>\n",
       "      <th>date_published</th>\n",
       "      <th>explanation</th>\n",
       "      <th>fact_checkers</th>\n",
       "      <th>label</th>\n",
       "      <th>main_text</th>\n",
       "      <th>sources</th>\n",
       "      <th>subjects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"The money the Clinton Foundation took from fr...</td>\n",
       "      <td>15661</td>\n",
       "      <td>April 26, 2015</td>\n",
       "      <td>\"Gingrich said the Clinton Foundation \"\"took m...</td>\n",
       "      <td>Katie Sanders</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Hillary Clinton is in the political crosshair...</td>\n",
       "      <td>https://www.wsj.com/articles/clinton-foundatio...</td>\n",
       "      <td>Foreign Policy, PunditFact, Newt Gingrich,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Annual Mammograms May Have More False-Positives</td>\n",
       "      <td>9893</td>\n",
       "      <td>October 18, 2011</td>\n",
       "      <td>This article reports on the results of a study...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>While the financial costs of screening mammogr...</td>\n",
       "      <td></td>\n",
       "      <td>Screening,WebMD,women's health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SBRT Offers Prostate Cancer Patients High Canc...</td>\n",
       "      <td>11358</td>\n",
       "      <td>September 28, 2016</td>\n",
       "      <td>This news release describes five-year outcomes...</td>\n",
       "      <td>Mary Chris Jaklevic,Steven J. Atlas, MD, MPH,K...</td>\n",
       "      <td>1</td>\n",
       "      <td>The news release quotes lead researcher Robert...</td>\n",
       "      <td>https://www.healthnewsreview.org/wp-content/up...</td>\n",
       "      <td>Association/Society news release,Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Study: Vaccine for Breast, Ovarian Cancer Has ...</td>\n",
       "      <td>10166</td>\n",
       "      <td>November 8, 2011</td>\n",
       "      <td>While the story does many things well, the ove...</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>The story does discuss costs, but the framing ...</td>\n",
       "      <td>http://clinicaltrials.gov/ct2/results?term=can...</td>\n",
       "      <td>Cancer,WebMD,women's health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Some appendicitis cases may not require ’emerg...</td>\n",
       "      <td>11276</td>\n",
       "      <td>September 20, 2010</td>\n",
       "      <td>We really don’t understand why only a handful ...</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>\"Although the story didn’t cite the cost of ap...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               claim claim_id  \\\n",
       "0  \"The money the Clinton Foundation took from fr...    15661   \n",
       "1    Annual Mammograms May Have More False-Positives     9893   \n",
       "2  SBRT Offers Prostate Cancer Patients High Canc...    11358   \n",
       "3  Study: Vaccine for Breast, Ovarian Cancer Has ...    10166   \n",
       "4  Some appendicitis cases may not require ’emerg...    11276   \n",
       "\n",
       "       date_published                                        explanation  \\\n",
       "0      April 26, 2015  \"Gingrich said the Clinton Foundation \"\"took m...   \n",
       "1    October 18, 2011  This article reports on the results of a study...   \n",
       "2  September 28, 2016  This news release describes five-year outcomes...   \n",
       "3    November 8, 2011  While the story does many things well, the ove...   \n",
       "4  September 20, 2010  We really don’t understand why only a handful ...   \n",
       "\n",
       "                                       fact_checkers  label  \\\n",
       "0                                      Katie Sanders      0   \n",
       "1                                                         1   \n",
       "2  Mary Chris Jaklevic,Steven J. Atlas, MD, MPH,K...      1   \n",
       "3                                                         2   \n",
       "4                                                         2   \n",
       "\n",
       "                                           main_text  \\\n",
       "0  \"Hillary Clinton is in the political crosshair...   \n",
       "1  While the financial costs of screening mammogr...   \n",
       "2  The news release quotes lead researcher Robert...   \n",
       "3  The story does discuss costs, but the framing ...   \n",
       "4  \"Although the story didn’t cite the cost of ap...   \n",
       "\n",
       "                                             sources  \\\n",
       "0  https://www.wsj.com/articles/clinton-foundatio...   \n",
       "1                                                      \n",
       "2  https://www.healthnewsreview.org/wp-content/up...   \n",
       "3  http://clinicaltrials.gov/ct2/results?term=can...   \n",
       "4                                                      \n",
       "\n",
       "                                      subjects  \n",
       "0  Foreign Policy, PunditFact, Newt Gingrich,   \n",
       "1               Screening,WebMD,women's health  \n",
       "2      Association/Society news release,Cancer  \n",
       "3                  Cancer,WebMD,women's health  \n",
       "4                                               "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"health_fact\")\n",
    "df_train = dataset['train'].to_pandas()\n",
    "\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has the following columns: \n",
      " \n",
      "['claim', 'claim_id', 'date_published', 'explanation', 'fact_checkers', 'label', 'main_text', 'sources', 'subjects']\n"
     ]
    }
   ],
   "source": [
    "print(f'The data has the following columns: \\n \\n{df_train.keys().tolist()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Claim' is concluded form the 'main_text'. Let's look at word distribution in these two attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9832.000000\n",
       "mean       13.934906\n",
       "std        15.677311\n",
       "min         0.000000\n",
       "25%         8.000000\n",
       "50%        11.000000\n",
       "75%        17.000000\n",
       "max       779.000000\n",
       "Name: claim, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['claim'].apply(\n",
    "    lambda s: len(s.split())).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9832.000000\n",
       "mean      711.881001\n",
       "std       513.193488\n",
       "min         0.000000\n",
       "25%       377.000000\n",
       "50%       607.000000\n",
       "75%       914.000000\n",
       "max      7067.000000\n",
       "Name: main_text, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['main_text'].apply(\n",
    "    lambda s: len(s.split())).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the number of words in 'main_text' is large, and the number of tokens in bert is limited, I will choose the top k sentences which are the most simillar to the claim. This code took a while to run. I ran using the code \"\" and saved the results as '.pkl' files and imported in next part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  0,  1,  2,  3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_label = df_train['label'].unique()\n",
    "num_label = len(np.where(unique_label>=0)[0])\n",
    "unique_label = np.sort(unique_label)\n",
    "unique_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These labels corresponds to \"true\", \"false\", \"unproven\" and \"mixture\". \"-1\" value is for classes other than the 4 mentioned classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of data with label -1: 28\n",
      "# of data with label 0: 3001\n",
      "# of data with label 1: 1434\n",
      "# of data with label 2: 5078\n",
      "# of data with label 3: 291\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'count')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_class = []\n",
    "for i in unique_label:\n",
    "    num_class += [df_train[df_train['label']==i].shape[0]]\n",
    "    print(f'# of data with label {i}: {num_class[-1]}')\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "plt.bar(unique_label, num_class)\n",
    "plt.xlabel('label_id')\n",
    "plt.ylabel('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of -1 class is not significant (28). So I will remove them from the dataset. The rest of the data are unbalanced. So I need to take care of it. I applied weights to the loss function to include the imbalanced data. The weights are calculated later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "The -1 labels are removed. Then the top 5 sentences in 'main_text' which are most simillar to 'claim' are chosen. The top 5 sentences and the claim are stored as 'picked_sen' in the dataframe. The code are as follwoing. However, I ran it once, and saved the data. So Later I will just load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = 'test'\n",
    "# dtp.Preprocess(dataset, name, K=5)\n",
    "\n",
    "# name = 'train'\n",
    "# dtp.Preprocess(dataset, name, K=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle(\"./output/train.pkl\")\n",
    "test = pd.read_pickle(\"./output/test.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the distribution of the picked_sen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f892c2a4c18>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "dist = train['picked_sen'].apply(\n",
    "    lambda s: len(s.split()))\n",
    "dist.plot.hist(bins=100, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I choose max_length of tokens=300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the weights of imbalanced data\n",
    "from sklearn.utils import class_weight\n",
    "class_weight = class_weight.compute_class_weight('balanced' ,np.unique(train['label']) ,train['label'])\n",
    "weights = torch.tensor(class_weight,dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These weights will be used to handle the unbalance data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Dataset: (9804, 3)\n",
      "TEST Dataset: (1233, 3)\n"
     ]
    }
   ],
   "source": [
    "# print(\"VAL Dataset: {}\".format(validation.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train.shape))\n",
    "print(\"TEST Dataset: {}\".format(test.shape))\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "training_set = dtp.HealthDataset(train, tokenizer, MAX_LEN)\n",
    "testing_set = dtp.HealthDataset(test, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating NN for fine tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader = DataLoader(training_set, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "testing_loader = DataLoader(testing_set, batch_size=VALID_BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERTClass(\n",
       "  (l1): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BERTClass()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the loss function and optimizer\n",
    "loss_function = torch.nn.CrossEntropyLoss(weight=weights)\n",
    "optimizer = torch.optim.Adam(params= model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tunning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "0/612.75 loss: 1.3957098722457886 \n",
      "Epoch:  0\n",
      "100/612.75 loss: 1.3860997091425526 \n",
      "Epoch:  0\n",
      "200/612.75 loss: 1.3700034232875007 \n",
      "Epoch:  0\n",
      "300/612.75 loss: 1.3602544192063848 \n",
      "Epoch:  0\n",
      "400/612.75 loss: 1.3538941356012055 \n",
      "Epoch:  0\n",
      "500/612.75 loss: 1.3443904206186474 \n",
      "Epoch:  0\n",
      "600/612.75 loss: 1.334652896927121 \n",
      "Epoch:  1\n",
      "0/612.75 loss: 1.1887375116348267 \n",
      "Epoch:  1\n",
      "100/612.75 loss: 1.2237645558791586 \n",
      "Epoch:  1\n",
      "200/612.75 loss: 1.2309113823952367 \n",
      "Epoch:  1\n",
      "300/612.75 loss: 1.221861411170706 \n",
      "Epoch:  1\n",
      "400/612.75 loss: 1.2070005907679437 \n",
      "Epoch:  1\n",
      "500/612.75 loss: 1.200740755437139 \n",
      "Epoch:  1\n",
      "600/612.75 loss: 1.1869384876503524 \n",
      "Epoch:  2\n",
      "0/612.75 loss: 1.2182551622390747 \n",
      "Epoch:  2\n",
      "100/612.75 loss: 1.121881628390586 \n",
      "Epoch:  2\n",
      "200/612.75 loss: 1.0952769298458573 \n",
      "Epoch:  2\n",
      "300/612.75 loss: 1.0950897642940383 \n",
      "Epoch:  2\n",
      "400/612.75 loss: 1.0899927000749736 \n",
      "Epoch:  2\n",
      "500/612.75 loss: 1.0853771574482947 \n",
      "Epoch:  2\n",
      "600/612.75 loss: 1.079885616774567 \n",
      "Epoch:  3\n",
      "0/612.75 loss: 1.2030956745147705 \n",
      "Epoch:  3\n",
      "100/612.75 loss: 1.0490447383115786 \n",
      "Epoch:  3\n",
      "200/612.75 loss: 1.0325931731741227 \n",
      "Epoch:  3\n",
      "300/612.75 loss: 1.036590848254207 \n",
      "Epoch:  3\n",
      "400/612.75 loss: 1.029845179688009 \n",
      "Epoch:  3\n",
      "500/612.75 loss: 1.0227949715065148 \n",
      "Epoch:  3\n",
      "600/612.75 loss: 1.0197484548298175 \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for _,data in enumerate(training_loader, 0):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(ids, mask)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        train_loss += loss.item()\n",
    "#         max_val_train, max_id_train = torch.max(outputs.data, dim=1)\n",
    "        if _%100==0:\n",
    "            print('Epoch: ', epoch )\n",
    "            print(\"\\r\" + \"{0}/{1} loss: {2} \".format(_, len(train) / TRAIN_BATCH_SIZE, train_loss / (_ + 1)))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "#     y_train = torch.cat((y_train, max_id_train), 0)\n",
    "    output_model_file = './model/model_' + str(epoch) + '.bin' \n",
    "    output_vocab_file = './model/vocab_' + str(epoch) + '.bin'\n",
    "    torch.save(model, output_model_file)\n",
    "    tokenizer.save_vocabulary(output_vocab_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately I couldn't run the code on gcp. This model is not converged yet. Moreover, I didn't perform hyperparameter tunning using the validation set. \n",
    "\n",
    "Anyway I brought the results for the model in next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./model/model_3.bin')\n",
    "model.eval()\n",
    "n_correct = 0; n_wrong = 0; total = 0;tr_loss=0\n",
    "nb_tr_examples=0;nb_tr_steps=0\n",
    "y_test = torch.empty((0))\n",
    "with torch.no_grad():\n",
    "    for _, data in enumerate(testing_loader, 0):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "#         targets = data['targets'].to(device, dtype = torch.long)\n",
    "        \n",
    "        Prob_test = model(ids, mask)\n",
    "        max_val_test, max_id_test = torch.max(Prob_test.data, dim=1)\n",
    "        y_test = torch.cat((y_test, max_id_test), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.13      0.19       388\n",
      "           1       0.17      0.26      0.21       201\n",
      "           2       0.49      0.38      0.43       599\n",
      "           3       0.04      0.31      0.08        45\n",
      "\n",
      "    accuracy                           0.28      1233\n",
      "   macro avg       0.26      0.27      0.23      1233\n",
      "weighted avg       0.37      0.28      0.30      1233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test['label'].tolist(), y_test, labels=[0, 1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
